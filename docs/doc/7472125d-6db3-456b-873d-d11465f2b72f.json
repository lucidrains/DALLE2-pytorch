{
    "summary": "This code defines ImageDataset and VQGanVAETrainer classes for loading image data and training a VAE model, setting parameters, optimizers, and creating loaders. It trains the model, logs losses, saves models, and tracks progress in a results folder.",
    "details": [
        {
            "comment": "This code contains several utility functions and helper methods. It includes import statements for various libraries, classes for data handling and model training, as well as custom functions for logging, looping, and user input.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/vqgan_vae_trainer.py\":0-46",
            "content": "from math import sqrt\nimport copy\nfrom random import choice\nfrom pathlib import Path\nfrom shutil import rmtree\nfrom PIL import Image\nimport torch\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchvision.transforms as T\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid, save_image\nfrom einops import rearrange\nfrom dalle2_pytorch.vqgan_vae import VQGanVAE\nfrom dalle2_pytorch.optimizer import get_optimizer\nfrom ema_pytorch import EMA\n# helpers\ndef exists(val):\n    return val is not None\ndef noop(*args, **kwargs):\n    pass\ndef cycle(dl):\n    while True:\n        for data in dl:\n            yield data\ndef cast_tuple(t):\n    return t if isinstance(t, (tuple, list)) else (t,)\ndef yes_or_no(question):\n    answer = input(f'{question} (y/n) ')\n    return answer.lower() in ('yes', 'y')\ndef accum_log(log, new_logs):\n    for key, new_value in new_logs.items():\n        old_value = log.get(key, 0.)\n        log[key] = old_value + new_value"
        },
        {
            "comment": "The code defines a class \"ImageDataset\" for loading and transforming image data, and a main trainer class \"VQGanVAETrainer\" for training a VAE model. The \"ImageDataset\" class initializes with a folder path, image size, and extension types to filter the images, then applies image transformations like converting to RGB mode, resizing, horizontal flipping, cropping, and tensor conversion. The \"VQGanVAETrainer\" class initializes with parameters like the VAE model, number of training steps, learning rate, and batch size for the training process.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/vqgan_vae_trainer.py\":47-90",
            "content": "    return log\n# classes\nclass ImageDataset(Dataset):\n    def __init__(\n        self,\n        folder,\n        image_size,\n        exts = ['jpg', 'jpeg', 'png']\n    ):\n        super().__init__()\n        self.folder = folder\n        self.image_size = image_size\n        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n        print(f'{len(self.paths)} training samples found at {folder}')\n        self.transform = T.Compose([\n            T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n            T.Resize(image_size),\n            T.RandomHorizontalFlip(),\n            T.CenterCrop(image_size),\n            T.ToTensor()\n        ])\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self, index):\n        path = self.paths[index]\n        img = Image.open(path)\n        return self.transform(img)\n# main trainer class\nclass VQGanVAETrainer(nn.Module):\n    def __init__(\n        self,\n        vae,\n        *,\n        num_train_steps,\n        lr,\n        batch_size,"
        },
        {
            "comment": "The code initializes an instance of a VQGanVAE and sets up various parameters for training. It checks if the provided vae is of type VQGanVAE, then assigns image size, creates an EMA model with specified update steps and intervals, registers a buffer for tracking steps, sets number of train steps, batch size, grad accumulation every, and initializes optimizer with specified learning rate and weight decay.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/vqgan_vae_trainer.py\":91-122",
            "content": "        folder,\n        grad_accum_every,\n        wd = 0.,\n        save_results_every = 100,\n        save_model_every = 1000,\n        results_folder = './results',\n        valid_frac = 0.05,\n        random_split_seed = 42,\n        ema_beta = 0.995,\n        ema_update_after_step = 500,\n        ema_update_every = 10,\n        apply_grad_penalty_every = 4,\n        amp = False\n    ):\n        super().__init__()\n        assert isinstance(vae, VQGanVAE), 'vae must be instance of VQGanVAE'\n        image_size = vae.image_size\n        self.vae = vae\n        self.ema_vae = EMA(vae, update_after_step = ema_update_after_step, update_every = ema_update_every)\n        self.register_buffer('steps', torch.Tensor([0]))\n        self.num_train_steps = num_train_steps\n        self.batch_size = batch_size\n        self.grad_accum_every = grad_accum_every\n        all_parameters = set(vae.parameters())\n        discr_parameters = set(vae.discr.parameters())\n        vae_parameters = all_parameters - discr_parameters\n        self.optim = get_optimizer(vae_parameters, lr = lr, wd = wd)"
        },
        {
            "comment": "This code initializes a Discriminator optimizer, Amplitude Signed-Precision (AMP) for mixed precision training, GradScaler for handling gradients, creates an ImageDataset from the given folder and image size, splits the dataset into training and validation if valid_frac is greater than 0, creates DataLoader for the dataset with specified batch_size and shuffle set to True.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/vqgan_vae_trainer.py\":123-149",
            "content": "        self.discr_optim = get_optimizer(discr_parameters, lr = lr, wd = wd)\n        self.amp = amp\n        self.scaler = GradScaler(enabled = amp)\n        self.discr_scaler = GradScaler(enabled = amp)\n        # create dataset\n        self.ds = ImageDataset(folder, image_size = image_size)\n        # split for validation\n        if valid_frac > 0:\n            train_size = int((1 - valid_frac) * len(self.ds))\n            valid_size = len(self.ds) - train_size\n            self.ds, self.valid_ds = random_split(self.ds, [train_size, valid_size], generator = torch.Generator().manual_seed(random_split_seed))\n            print(f'training with dataset of {len(self.ds)} samples and validating with randomly splitted {len(self.valid_ds)} samples')\n        else:\n            self.valid_ds = self.ds\n            print(f'training with shared training and valid dataset of {len(self.ds)} samples')\n        # dataloader\n        self.dl = cycle(DataLoader(\n            self.ds,\n            batch_size = batch_size,\n            shuffle = True"
        },
        {
            "comment": "The code initializes the valid data loader and sets parameters for saving models, results, and applying gradient penalty. It checks if previous experiment checkpoints and results should be cleared, creates the results folder if needed, and defines the train_step function for training the VAE (generator).",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/vqgan_vae_trainer.py\":150-187",
            "content": "        ))\n        self.valid_dl = cycle(DataLoader(\n            self.valid_ds,\n            batch_size = batch_size,\n            shuffle = True\n        ))\n        self.save_model_every = save_model_every\n        self.save_results_every = save_results_every\n        self.apply_grad_penalty_every = apply_grad_penalty_every\n        self.results_folder = Path(results_folder)\n        if len([*self.results_folder.glob('**/*')]) > 0 and yes_or_no('do you want to clear previous experiment checkpoints and results?'):\n            rmtree(str(self.results_folder))\n        self.results_folder.mkdir(parents = True, exist_ok = True)\n    def train_step(self):\n        device = next(self.vae.parameters()).device\n        steps = int(self.steps.item())\n        apply_grad_penalty = not (steps % self.apply_grad_penalty_every)\n        self.vae.train()\n        # logs\n        logs = {}\n        # update vae (generator)\n        for _ in range(self.grad_accum_every):\n            img = next(self.dl)\n            img = img.to(device)\n            with autocast(enabled = self.amp):"
        },
        {
            "comment": "This code trains a VAE model and updates the discriminator. It uses scaling, accumulation, and gradients for efficient backpropagation. The loss is calculated and logged for both VAE and discriminator, then optimizers are updated.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/vqgan_vae_trainer.py\":188-220",
            "content": "                loss = self.vae(\n                    img,\n                    return_loss = True,\n                    apply_grad_penalty = apply_grad_penalty\n                )\n                self.scaler.scale(loss / self.grad_accum_every).backward()\n            accum_log(logs, {'loss': loss.item() / self.grad_accum_every})\n        self.scaler.step(self.optim)\n        self.scaler.update()\n        self.optim.zero_grad()\n        # update discriminator\n        if exists(self.vae.discr):\n            discr_loss = 0\n            for _ in range(self.grad_accum_every):\n                img = next(self.dl)\n                img = img.to(device)\n                with autocast(enabled = self.amp):\n                    loss = self.vae(img, return_discr_loss = True)\n                    self.discr_scaler.scale(loss / self.grad_accum_every).backward()\n                accum_log(logs, {'discr_loss': loss.item() / self.grad_accum_every})\n            self.discr_scaler.step(self.discr_optim)\n            self.discr_scaler.update()\n            self.discr_optim.zero_grad()"
        },
        {
            "comment": "This code snippet logs the VAE and discriminator losses, updates the exponential moving average (EMA) generator model, saves models every save_results_every steps, and generates and saves reconstruction images for training.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/vqgan_vae_trainer.py\":222-250",
            "content": "            # log\n            print(f\"{steps}: vae loss: {logs['loss']} - discr loss: {logs['discr_loss']}\")\n        # update exponential moving averaged generator\n        self.ema_vae.update()\n        # sample results every so often\n        if not (steps % self.save_results_every):\n            for model, filename in ((self.ema_vae.ema_model, f'{steps}.ema'), (self.vae, str(steps))):\n                model.eval()\n                imgs = next(self.dl)\n                imgs = imgs.to(device)\n                recons = model(imgs)\n                nrows = int(sqrt(self.batch_size))\n                imgs_and_recons = torch.stack((imgs, recons), dim = 0)\n                imgs_and_recons = rearrange(imgs_and_recons, 'r b ... -> (b r) ...')\n                imgs_and_recons = imgs_and_recons.detach().cpu().float().clamp(0., 1.)\n                grid = make_grid(imgs_and_recons, nrow = 2, normalize = True, value_range = (0, 1))\n                logs['reconstructions'] = grid\n                save_image(grid, str(self.results_folder / f'{filename}.png'))"
        },
        {
            "comment": "Saves the VAE model and EMA-VAE model periodically during training, tracking progress in specified results folder.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/vqgan_vae_trainer.py\":252-277",
            "content": "            print(f'{steps}: saving to {str(self.results_folder)}')\n        # save model every so often\n        if not (steps % self.save_model_every):\n            state_dict = self.vae.state_dict()\n            model_path = str(self.results_folder / f'vae.{steps}.pt')\n            torch.save(state_dict, model_path)\n            ema_state_dict = self.ema_vae.state_dict()\n            model_path = str(self.results_folder / f'vae.{steps}.ema.pt')\n            torch.save(ema_state_dict, model_path)\n            print(f'{steps}: saving model to {str(self.results_folder)}')\n        self.steps += 1\n        return logs\n    def train(self, log_fn = noop):\n        device = next(self.vae.parameters()).device\n        while self.steps < self.num_train_steps:\n            logs = self.train_step()\n            log_fn(logs)\n        print('training complete')"
        }
    ]
}