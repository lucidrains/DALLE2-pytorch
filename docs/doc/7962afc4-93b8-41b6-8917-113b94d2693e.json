{
    "summary": "This code trains a Diffusion Prior model using PyTorch and DALLE2-pytorch library, with functions for creating the model, training, data loading, acceleration, evaluation, text-image similarity comparison, backpropagation, logging, saving best models, measuring speed, resetting validation timers, handling errors, saving models, and initializing training with data loaders and HFA setup.",
    "details": [
        {
            "comment": "This code is for training a Diffusion Prior model using PyTorch and the DALLE2-pytorch library. It defines functions to create the model, configure the training process, and load data. The cosine similarity function is used for comparison, and there are helper functions to check if values exist and if they fall within specified bounds. The code also uses accelerate for efficient training and allows for device specification (CPU or GPU) and an optional accelerator instance for further optimization.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":0-44",
            "content": "import click\nimport torch\nfrom torch import nn\nfrom typing import List\nfrom accelerate import Accelerator\nfrom accelerate.utils import set_seed\nfrom torch.utils.data import DataLoader\nfrom embedding_reader import EmbeddingReader\nfrom accelerate.utils import dataclasses as accelerate_dataclasses\nfrom dalle2_pytorch.utils import Timer\nfrom dalle2_pytorch.trackers import Tracker\nfrom dalle2_pytorch import DiffusionPriorTrainer\nfrom dalle2_pytorch.dataloaders import get_reader, make_splits\nfrom dalle2_pytorch.train_configs import (\n    DiffusionPriorConfig,\n    DiffusionPriorTrainConfig,\n    TrainDiffusionPriorConfig,\n)\n# helpers\ncos = nn.CosineSimilarity(dim=1, eps=1e-6)\ndef exists(val):\n    return val is not None\ndef all_between(values: list, lower_bound, upper_bound):\n    for value in values:\n        if value < lower_bound or value > upper_bound:\n            return False\n    return True\ndef make_model(\n    prior_config: DiffusionPriorConfig,\n    train_config: DiffusionPriorTrainConfig,\n    device: str = None,\n    accelerator: Accelerator = None,"
        },
        {
            "comment": "This code defines a function `create_trainer` that takes in a `prior_config`, and creates a `DiffusionPriorTrainer` object with specified parameters. It also defines the `create_tracker` function, which creates a `Tracker` object based on the provided configuration. The functions return the created objects.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":45-82",
            "content": "):\n    # create model from config\n    diffusion_prior = prior_config.create()\n    # instantiate the trainer\n    trainer = DiffusionPriorTrainer(\n        diffusion_prior=diffusion_prior,\n        lr=train_config.lr,\n        wd=train_config.wd,\n        max_grad_norm=train_config.max_grad_norm,\n        amp=train_config.amp,\n        use_ema=train_config.use_ema,\n        device=device,\n        accelerator=accelerator,\n        warmup_steps=train_config.warmup_steps,\n    )\n    return trainer\ndef create_tracker(\n    accelerator: Accelerator,\n    config: TrainDiffusionPriorConfig,\n    config_path: str,\n    dummy: bool = False,\n) -> Tracker:\n    tracker_config = config.tracker\n    accelerator_config = {\n        \"Distributed\": accelerator.distributed_type\n        != accelerate_dataclasses.DistributedType.NO,\n        \"DistributedType\": accelerator.distributed_type,\n        \"NumProcesses\": accelerator.num_processes,\n        \"MixedPrecision\": accelerator.mixed_precision,\n    }\n    tracker: Tracker = tracker_config.create(\n        config, accelerator_config, dummy_mode=dummy"
        },
        {
            "comment": "This function pads a value or tensor across all processes, gathers them and reduces them to a single average. It works with tensors of type \"mean\", \"sum\", \"max\", and \"min\". If the resulting tensor is empty, it returns None. It first waits for everyone to arrive before gathering, converts the input to a tensor if it's not already, and ensures that the tensor is on the proper device.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":83-121",
            "content": "    )\n    tracker.save_config(config_path, config_name=\"prior_config.json\")\n    return tracker\ndef pad_gather_reduce(trainer: DiffusionPriorTrainer, x, method=\"mean\"):\n    \"\"\"\n    pad a value or tensor across all processes and gather\n    params:\n        - trainer: a trainer that carries an accelerator object\n        - x: a number or torch tensor to reduce\n        - method: \"mean\", \"sum\", \"max\", \"min\"\n    return:\n        - the average tensor after maskin out 0's\n        - None if the gather resulted in an empty tensor\n    \"\"\"\n    assert method in [\n        \"mean\",\n        \"sum\",\n        \"max\",\n        \"min\",\n    ], \"This function has limited capabilities [sum, mean, max, min]\"\n    assert type(x) is not None, \"Cannot reduce a None type object\"\n    # wait for everyone to arrive here before gathering\n    if type(x) is not torch.Tensor:\n        x = torch.tensor([x])\n    # verify that the tensor is on the proper device\n    x = x.to(trainer.device)\n    # pad across processes\n    padded_x = trainer.accelerator.pad_across_processes(x, dim=0)"
        },
        {
            "comment": "The code gathers tensor data across all processes, masks out zeros, and handles empty tensors. It then calculates the mean, sum, maximum, or minimum of the masked tensor depending on the method specified. The save_trainer function logs the model with an appropriate method based on the tracker.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":123-159",
            "content": "    # gather across all procesess\n    gathered_x = trainer.accelerator.gather(padded_x)\n    # mask out zeros\n    masked_x = gathered_x[gathered_x != 0]\n    # if the tensor is empty, warn and return None\n    if len(masked_x) == 0:\n        click.secho(\n            f\"The call to this method resulted in an empty tensor after masking out zeros. The gathered tensor was this: {gathered_x} and the original value passed was: {x}.\",\n            fg=\"red\",\n        )\n        return None\n    if method == \"mean\":\n        return torch.mean(masked_x)\n    elif method == \"sum\":\n        return torch.sum(masked_x)\n    elif method == \"max\":\n        return torch.max(masked_x)\n    elif method == \"min\":\n        return torch.min(masked_x)\ndef save_trainer(\n    tracker: Tracker,\n    trainer: DiffusionPriorTrainer,\n    is_latest: bool,\n    is_best: bool,\n    epoch: int,\n    samples_seen: int,\n    best_validation_loss: float,\n):\n    \"\"\"\n    Logs the model with an appropriate method depending on the tracker\n    \"\"\"\n    trainer.accelerator.wait_for_everyone()"
        },
        {
            "comment": "This code is part of a model training process. It saves the model at certain intervals and loads it later depending on the tracker type. The save function reports whether the saved model is best or latest, and the recall_trainer function loads the model with an appropriate method based on the tracker's loader type. Additionally, there are functions for evaluating validation loss.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":161-200",
            "content": "    if trainer.accelerator.is_main_process:\n        click.secho(\n            f\"RANK:{trainer.accelerator.process_index} | Saving Model | Best={is_best} | Latest={is_latest}\",\n            fg=\"magenta\",\n        )\n    tracker.save(\n        trainer=trainer,\n        is_best=is_best,\n        is_latest=is_latest,\n        epoch=int(epoch),\n        samples_seen=int(samples_seen),\n        best_validation_loss=best_validation_loss,\n    )\ndef recall_trainer(tracker: Tracker, trainer: DiffusionPriorTrainer):\n    \"\"\"\n    Loads the model with an appropriate method depending on the tracker\n    \"\"\"\n    if trainer.accelerator.is_main_process:\n        click.secho(f\"Loading model from {type(tracker.loader).__name__}\", fg=\"yellow\")\n    state_dict = tracker.recall()\n    trainer.load(state_dict, strict=True)\n    return (\n        int(state_dict.get(\"epoch\", 0)),\n        state_dict.get(\"best_validation_loss\", 0),\n        int(state_dict.get(\"samples_seen\", 0)),\n    )\n# eval functions\ndef report_validation_loss(\n    trainer: DiffusionPriorTrainer,"
        },
        {
            "comment": "This code measures validation loss on a given data subset, using an optional EMA model and text conditioning. It iterates through a dataloader, computes losses for each batch, accumulates them in total_loss, and finally returns the average loss. The progress is echoed if the process is the main one.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":201-238",
            "content": "    dataloader: DataLoader,\n    text_conditioned: bool,\n    use_ema: bool,\n    tracker: Tracker,\n    split: str,\n    tracker_folder: str,\n    loss_type: str,\n):\n    \"\"\"\n    Compute the validation loss on a given subset of data.\n    \"\"\"\n    if trainer.accelerator.is_main_process:\n        click.secho(\n            f\"Measuring performance on {use_ema}-{split} split\",\n            fg=\"green\",\n            blink=True,\n        )\n    total_loss = torch.zeros(1, dtype=torch.float, device=trainer.device)\n    for image_embeddings, text_data in dataloader:\n        image_embeddings = image_embeddings.to(trainer.device)\n        text_data = text_data.to(trainer.device)\n        input_args = dict(image_embed=image_embeddings)\n        if text_conditioned:\n            input_args = dict(**input_args, text=text_data)\n        else:\n            input_args = dict(**input_args, text_embed=text_data)\n        if use_ema:\n            loss = trainer.ema_diffusion_prior(**input_args)\n        else:\n            loss = trainer(**input_args)\n        total_loss += loss"
        },
        {
            "comment": "This code measures the cosine similarity on a given split with specified timesteps. It first sets the trainer to evaluation mode and then iterates through each batch of data from the dataloader. Within this loop, it moves both test image embeddings and text data to the device used by the trainer. If the model is text-conditioned, it generates an embedding from the tokenized text using the `embed_text` function provided by the trainer. This information can be useful for understanding how this code measures cosine similarity in a given context.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":240-274",
            "content": "    # compute the average loss across all processes\n    avg_loss = pad_gather_reduce(trainer, total_loss, method=\"mean\")\n    stats = {f\"{tracker_folder}/{loss_type}-loss\": avg_loss}\n    # print and log results on main process\n    tracker.log(stats, step=trainer.step.item() + 1)\n    return avg_loss\ndef report_cosine_sims(\n    trainer: DiffusionPriorTrainer,\n    dataloader: DataLoader,\n    text_conditioned: bool,\n    tracker: Tracker,\n    split: str,\n    timesteps: int,\n    tracker_folder: str,\n):\n    trainer.eval()\n    if trainer.accelerator.is_main_process:\n        click.secho(\n            f\"Measuring Cosine-Similarity on {split} split with {timesteps} timesteps\",\n            fg=\"green\",\n            blink=True,\n        )\n    for test_image_embeddings, text_data in dataloader:\n        test_image_embeddings = test_image_embeddings.to(trainer.device)\n        text_data = text_data.to(trainer.device)\n        # we are text conditioned, we produce an embedding from the tokenized text\n        if text_conditioned:\n            text_embedding, text_encodings = trainer.embed_text(text_data)"
        },
        {
            "comment": "This code shuffles text embeddings and encodings to simulate \"unrelated\" captions for training the diffusion model. If text-conditioned, it also shuffles the text condition. It prepares both text and image embeddings.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":275-302",
            "content": "            text_cond = dict(text_embed=text_embedding, text_encodings=text_encodings)\n        else:\n            text_embedding = text_data\n            text_cond = dict(text_embed=text_embedding)\n        # make a copy of the text embeddings for shuffling\n        text_embed_shuffled = text_embedding.clone()\n        # roll the text to simulate \"unrelated\" captions\n        rolled_idx = torch.roll(torch.arange(text_embedding.shape[0]), 1)\n        text_embed_shuffled = text_embed_shuffled[rolled_idx]\n        text_embed_shuffled = text_embed_shuffled / text_embed_shuffled.norm(\n            dim=1, keepdim=True\n        )\n        if text_conditioned:\n            text_encodings_shuffled = text_encodings[rolled_idx]\n        else:\n            text_encodings_shuffled = None\n        text_cond_shuffled = dict(\n            text_embed=text_embed_shuffled, text_encodings=text_encodings_shuffled\n        )\n        # prepare the text embedding\n        text_embed = text_embedding / text_embedding.norm(dim=1, keepdim=True)\n        # prepare image embeddings"
        },
        {
            "comment": "This code calculates the similarity between text embeddings and image embeddings, then shuffles the text embeddings to create unrelated pairs. It uses diffusion models for prediction and normalizes the embeddings. The final step is calculating the similarities using cosine similarity and mean reduction method.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":303-333",
            "content": "        test_image_embeddings = test_image_embeddings / test_image_embeddings.norm(\n            dim=1, keepdim=True\n        )\n        # predict on the unshuffled text embeddings\n        predicted_image_embeddings = trainer.p_sample_loop(\n            test_image_embeddings.shape,\n            text_cond,\n            timesteps=timesteps,\n        )\n        predicted_image_embeddings = (\n            predicted_image_embeddings\n            / predicted_image_embeddings.norm(dim=1, keepdim=True)\n        )\n        # predict on the shuffled embeddings\n        predicted_unrelated_embeddings = trainer.p_sample_loop(\n            test_image_embeddings.shape,\n            text_cond_shuffled,\n            timesteps=timesteps,\n        )\n        predicted_unrelated_embeddings = (\n            predicted_unrelated_embeddings\n            / predicted_unrelated_embeddings.norm(dim=1, keepdim=True)\n        )\n        # calculate similarities\n        orig_sim = pad_gather_reduce(\n            trainer, cos(text_embed, test_image_embeddings), method=\"mean\""
        },
        {
            "comment": "This code calculates similarity scores between embeddings of text, predicted images, and original images. It then logs these scores for various steps in the training process to track progress.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":334-359",
            "content": "        )\n        pred_sim = pad_gather_reduce(\n            trainer, cos(text_embed, predicted_image_embeddings), method=\"mean\"\n        )\n        unrel_sim = pad_gather_reduce(\n            trainer, cos(text_embed, predicted_unrelated_embeddings), method=\"mean\"\n        )\n        pred_img_sim = pad_gather_reduce(\n            trainer,\n            cos(test_image_embeddings, predicted_image_embeddings),\n            method=\"mean\",\n        )\n        stats = {\n            f\"{tracker_folder}/baseline similarity [steps={timesteps}]\": orig_sim,\n            f\"{tracker_folder}/similarity with text [steps={timesteps}]\": pred_sim,\n            f\"{tracker_folder}/similarity with original image [steps={timesteps}]\": pred_img_sim,\n            f\"{tracker_folder}/similarity with unrelated caption [steps={timesteps}]\": unrel_sim,\n            f\"{tracker_folder}/difference from baseline similarity [steps={timesteps}]\": pred_sim\n            - orig_sim,\n        }\n        tracker.log(stats, step=trainer.step.item() + 1)\ndef eval_model("
        },
        {
            "comment": "This function runs evaluation on a model, tracks metrics, and returns the loss if requested. It uses DiffusionPriorTrainer and DataLoader. The use_ema parameter is used to differentiate between an Exponential Moving Average (EMA) model and an online (current) model. It checks whether the timesteps are valid for the model's noise scheduler. It also measures cosine metrics across various eta and timesteps if report_cosine is set to True.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":360-397",
            "content": "    trainer: DiffusionPriorTrainer,\n    dataloader: DataLoader,\n    text_conditioned: bool,\n    split: str,\n    tracker: Tracker,\n    use_ema: bool,\n    report_cosine: bool,\n    report_loss: bool,\n    timesteps: List[int],\n    loss_type: str = None,\n):\n    \"\"\"\n    Run evaluation on a model and track metrics\n    returns: loss if requested\n    \"\"\"\n    trainer.eval()\n    use_ema = \"ema\" if use_ema else \"online\"\n    tracker_folder = f\"metrics/{use_ema}-{split}\"\n    # detemine if valid timesteps are passed\n    min_timesteps = trainer.accelerator.unwrap_model(\n        trainer.diffusion_prior\n    ).sample_timesteps\n    max_timesteps = trainer.accelerator.unwrap_model(\n        trainer.diffusion_prior\n    ).noise_scheduler.num_timesteps\n    assert all_between(\n        timesteps, lower_bound=min_timesteps, upper_bound=max_timesteps\n    ), f\"all timesteps values must be between {min_timesteps} and {max_timesteps}: got {timesteps}\"\n    # measure cosine metrics across various eta and timesteps\n    if report_cosine:\n        for timestep in timesteps:"
        },
        {
            "comment": "This code measures cosine similarity on a separate dataset and reports the loss on another split of data in a training script. It also initializes timers for saving, measuring samples per second, and tracking validation time.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":398-439",
            "content": "            report_cosine_sims(\n                trainer,\n                dataloader=dataloader,\n                text_conditioned=text_conditioned,\n                tracker=tracker,\n                split=split,\n                timesteps=timestep,\n                tracker_folder=tracker_folder,\n            )\n    # measure loss on a seperate split of data\n    if report_loss:\n        loss = report_validation_loss(\n            trainer=trainer,\n            dataloader=dataloader,\n            text_conditioned=text_conditioned,\n            use_ema=use_ema,\n            tracker=tracker,\n            split=split,\n            tracker_folder=tracker_folder,\n            loss_type=loss_type,\n        )\n        return loss\n# training script\ndef train(\n    trainer: DiffusionPriorTrainer,\n    tracker: Tracker,\n    train_loader: DataLoader,\n    eval_loader: DataLoader,\n    test_loader: DataLoader,\n    config: DiffusionPriorTrainConfig,\n):\n    # init timers\n    save_timer = Timer()  # when to save\n    samples_timer = Timer()  # samples/sec\n    validation_profiler = Timer()  # how long is validation taking"
        },
        {
            "comment": "The code sets up a training loop that iterates over epochs and resets the dataloader if it was paused mid-epoch. It places data on the device, tracks the best validation loss, and keeps track of samples seen.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":440-470",
            "content": "    validation_countdown = Timer()  # when to perform evalutation\n    # keep track of best validation loss\n    best_validation_loss = config.train.best_validation_loss\n    samples_seen = config.train.num_samples_seen\n    # do training\n    start_epoch = config.train.current_epoch\n    for epoch in range(start_epoch, config.train.epochs):\n        # if we finished out an old epoch, reset the distribution to be a full epoch\n        tracker.log({\"tracking/epoch\": epoch}, step=trainer.step.item())\n        if train_loader.dataset.get_start() > 0 and epoch == start_epoch+1:\n            if trainer.accelerator.is_main_process:\n                click.secho(f\"Finished resumed epoch...resetting dataloader.\")\n            train_loader.dataset.set_start(0)\n        for img, txt in train_loader:\n            # setup things every step\n            trainer.train()\n            current_step = trainer.step.item()\n            samples_timer.reset()\n            # place data on device\n            img = img.to(trainer.device)\n            txt = txt.to(trainer.device)"
        },
        {
            "comment": "This code is performing backpropagation, updating the exponential moving average (EMA), logging training metrics, and tracking evaluation intervals. It calculates the loss from text and image embeddings using the trainer model and updates the EMA diffusion prior. Metrics like samples per second, number of samples seen, EMA decay, and a specific loss type are logged at each step, while evaluating the validation countdown time interval for metrics tracking.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":472-503",
            "content": "            # pass to model\n            loss = trainer(text=txt, image_embed=img)\n            # perform backprop & apply EMA updates\n            trainer.update()\n            # gather info about training step\n            all_loss = pad_gather_reduce(trainer, loss, method=\"mean\")\n            num_samples = pad_gather_reduce(trainer, len(txt), method=\"sum\")\n            samples_per_sec = num_samples / samples_timer.elapsed()\n            samples_seen += num_samples\n            ema_decay = trainer.ema_diffusion_prior.get_current_decay()\n            # log\n            tracker.log(\n                {\n                    \"tracking/samples-sec\": samples_per_sec,\n                    \"tracking/samples-seen\": samples_seen,\n                    \"tracking/ema-decay\": ema_decay,\n                    f\"tracking/training-{config.prior.loss_type}\": all_loss,\n                },\n                step=current_step,\n            )\n            # Metric Tracking @ Timed Intervals\n            eval_delta = pad_gather_reduce(\n                trainer, validation_countdown.elapsed(), method=\"min\""
        },
        {
            "comment": "This code is evaluating the model on validation data with specified options. It checks if it's time to evaluate, resets the profiler for timing, packages evaluation kwargs, and calls eval_model function with dataloader, loss type, split (validation), use_ema, report_cosine, report_loss, and eval_kwargs. It also evaluates the ema model separately.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":504-535",
            "content": "            )\n            if eval_delta != None and eval_delta > config.data.eval_every_seconds:\n                # begin timing how long this takes\n                validation_profiler.reset()\n                # package kwargs for evaluation\n                eval_kwargs = {\n                    \"trainer\": trainer,\n                    \"tracker\": tracker,\n                    \"text_conditioned\": config.prior.condition_on_text_encodings,\n                    \"timesteps\": config.train.eval_timesteps,\n                }\n                # ONLINE MODEL : COSINE : LOSS : VALIDATION SPLIT\n                eval_model(\n                    dataloader=eval_loader,\n                    loss_type=config.prior.loss_type,\n                    split=\"validation\",\n                    use_ema=False,\n                    report_cosine=False,\n                    report_loss=True,\n                    **eval_kwargs,\n                )\n                # EMA MODEL : COSINE : LOSS : VALIDATION DATA\n                ema_val_loss = eval_model(\n                    dataloader=eval_loader,"
        },
        {
            "comment": "In this code, a validation process is executed using ema (exponential moving average) to calculate the loss. The lowest ema validation loss seen so far is stored in `best_validation_loss` and if the current validation loss is lower than the previous best, the model is saved as the 'best' model. This code also logs the time taken for the validation process.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":536-565",
            "content": "                    loss_type=config.prior.loss_type,\n                    split=\"validation\",\n                    use_ema=True,\n                    report_cosine=True,\n                    report_loss=True,\n                    **eval_kwargs,\n                )\n                tracker.log(\n                    {\n                        \"tracking/validation length (minutes)\": validation_profiler.elapsed()\n                        / 60\n                    }\n                )\n                # check if the ema validation is the lowest seen yet\n                if ema_val_loss < best_validation_loss:\n                    best_validation_loss = ema_val_loss\n                    #  go save the model as best\n                    save_trainer(\n                        trainer=trainer,\n                        tracker=tracker,\n                        is_best=True,\n                        is_latest=False,\n                        samples_seen=samples_seen,\n                        epoch=epoch,\n                        best_validation_loss=best_validation_loss,"
        },
        {
            "comment": "This code segment resets the validation timer and handles errors in reading eval and save times. It saves the latest model if the elapsed time meets a certain condition, and resets the save timer. This helps keep track of the training progress and ensures timely saving of models for later use.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":566-597",
            "content": "                    )\n                # reset timer for validaiton\n                validation_countdown.reset()\n            elif eval_delta is None:\n                click.secho(\n                    f\"Error occured reading the eval time on rank: {trainer.device}\",\n                    fg=\"yellow\",\n                )\n            # save as latest model on schedule\n            save_delta = pad_gather_reduce(trainer, save_timer.elapsed(), method=\"min\")\n            if save_delta != None and save_delta >= config.train.save_every_seconds:\n                save_trainer(\n                    trainer=trainer,\n                    tracker=tracker,\n                    is_best=False,\n                    is_latest=True,\n                    samples_seen=samples_seen,\n                    epoch=epoch,\n                    best_validation_loss=best_validation_loss,\n                )\n                save_timer.reset()\n            elif save_delta is None:\n                click.secho(\n                    f\"Error occured reading the save time on rank: {trainer.device}\","
        },
        {
            "comment": "Starting test phase and saving the last model as latest before validation. If test loss is lower than previous best validation loss, it will be saved as the new best model.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":598-639",
            "content": "                    fg=\"yellow\",\n                )\n    # evaluate on test data\n    if trainer.accelerator.is_main_process:\n        click.secho(f\"Starting Test\", fg=\"red\")\n    # save one last time as latest before beginning validation\n    save_trainer(\n        tracker=tracker,\n        trainer=trainer,\n        is_best=False,\n        is_latest=True,\n        samples_seen=samples_seen,\n        epoch=epoch,\n        best_validation_loss=best_validation_loss,\n    )\n    test_loss = eval_model(\n        trainer=trainer,\n        dataloader=test_loader,\n        text_conditioned=config.prior.condition_on_text_encodings,\n        split=\"test\",\n        tracker=tracker,\n        use_ema=True,\n        report_cosine=False,\n        report_loss=True,\n        timesteps=config.train.eval_timesteps,\n        loss_type=config.prior.loss_type,\n    )\n    if test_loss < best_validation_loss:\n        best_validation_loss = test_loss\n        #  go save the model as best\n        save_trainer(\n            trainer=trainer,\n            tracker=tracker,\n            is_best=True,"
        },
        {
            "comment": "The function initialize_training is responsible for loading the configuration file, setting the seed, getting a device, making the trainer, and creating a tracker. The trainer is automatically distributed if possible and configured. Additionally, the function checks whether it can recall from a checkpoint.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":640-680",
            "content": "            is_latest=False,\n            samples_seen=samples_seen,\n            epoch=epoch,\n            best_validation_loss=test_loss,\n        )\ndef initialize_training(config_file, accelerator):\n    \"\"\"\n    Parse the configuration file, and prepare everything necessary for training\n    \"\"\"\n    # load the configuration file\n    if accelerator.is_main_process:\n        click.secho(f\"Loading configuration from {config_file}\", fg=\"green\")\n    config = TrainDiffusionPriorConfig.from_json_path(config_file)\n    # seed\n    set_seed(config.train.random_seed)\n    # get a device\n    device = accelerator.device\n    # make the trainer (will automatically distribute if possible & configured)\n    trainer: DiffusionPriorTrainer = make_model(\n        config.prior, config.train, device, accelerator\n    ).to(device)\n    # create a tracker\n    tracker = create_tracker(\n        accelerator, config, config_file, dummy=accelerator.process_index != 0\n    )\n    # reload from chcekpoint\n    if tracker.can_recall:\n        current_epoch, best_validation_loss, samples_seen = recall_trainer("
        },
        {
            "comment": "This code block displays the current epoch, best validation loss, and samples seen, updates configuration with recalled values, fetches and prepares data for training by creating a loader, and calculates the start point within the epoch.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":681-710",
            "content": "            tracker=tracker, trainer=trainer\n        )\n        # display best values\n        if trainer.accelerator.is_main_process:\n            click.secho(f\"Current Epoch: {current_epoch} | Best Val Loss: {best_validation_loss} | Samples Seen: {samples_seen}\", fg=\"yellow\")\n        # update config to reflect recalled values\n        config.train.num_samples_seen = samples_seen\n        config.train.current_epoch = current_epoch\n        config.train.best_validation_loss = best_validation_loss\n    # fetch and prepare data\n    if trainer.accelerator.is_main_process:\n        click.secho(\"Grabbing data...\", fg=\"blue\", blink=True)\n    trainer.accelerator.wait_for_everyone()\n    img_reader = get_reader(\n        text_conditioned=trainer.text_conditioned,\n        img_url=config.data.image_url,\n        meta_url=config.data.meta_url,\n    )\n    # calculate start point within epoch\n    trainer.accelerator.wait_for_everyone()\n    train_loader, eval_loader, test_loader = make_splits(\n        text_conditioned=trainer.text_conditioned,"
        },
        {
            "comment": "This code initializes a data loader and sets the start point for resuming training if necessary. It ensures that the training continues from where it left off in a previous run by adjusting the number of samples seen based on the total number of data points and the current epoch. The main process prints a message indicating the resumption sample count.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":711-742",
            "content": "        batch_size=config.data.batch_size,\n        num_data_points=config.data.num_data_points,\n        train_split=config.data.splits.train,\n        eval_split=config.data.splits.val,\n        image_reader=img_reader,\n        rank=accelerator.state.process_index,\n        world_size=accelerator.state.num_processes,\n        start=0,\n    )\n    # update the start point to finish out the epoch on a resumed run\n    if tracker.can_recall:\n        samples_seen = config.train.num_samples_seen\n        length = (\n            config.data.num_data_points\n            if samples_seen <= img_reader.count\n            else img_reader.count\n        )\n        scaled_samples = length * config.train.current_epoch\n        start_point = (\n            scaled_samples - samples_seen if scaled_samples > samples_seen else samples_seen\n        )\n        if trainer.accelerator.is_main_process:\n            click.secho(f\"Resuming at sample: {start_point}\", fg=\"yellow\")\n        train_loader.dataset.set_start(start_point)\n    # start training\n    if trainer.accelerator.is_main_process:"
        },
        {
            "comment": "Beginning Prior Training message with distributed status. Then, initiates training process using provided configurations and loaders for trainer, tracker, train_loader, eval_loader, and test_loader. Finally, executes main function with the specified config file to start Heterogeneous Fusion Acceleration (HFA) and set up the training environment.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/train_diffusion_prior.py\":743-769",
            "content": "        click.secho(\n            f\"Beginning Prior Training : Distributed={accelerator.state.distributed_type != accelerate_dataclasses.DistributedType.NO}\",\n            fg=\"yellow\",\n        )\n    train(\n        trainer=trainer,\n        tracker=tracker,\n        train_loader=train_loader,\n        eval_loader=eval_loader,\n        test_loader=test_loader,\n        config=config,\n    )\n@click.command()\n@click.option(\"--config_file\", default=\"configs/train_prior_config.example.json\")\ndef main(config_file):\n    # start HFA\n    accelerator = Accelerator()\n    # setup training\n    initialize_training(config_file, accelerator)\nif __name__ == \"__main__\":\n    main()"
        }
    ]
}