{
    "summary": "The code initializes DeepSpeed's trainer, sets model parameters, distributes the model, and handles precision. It also initializes optimizers and schedulers, prepares dataloaders, validates compatibility, performs computations, and returns total loss.",
    "details": [
        {
            "comment": "The code imports various libraries and defines several utility functions for working with tensors, learning rates, optimizers, and distributed training. It also includes helper functions to handle default values and handle dictionaries. These utilities are likely used throughout the codebase to train and evaluate models efficiently.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":0-42",
            "content": "import time\nimport copy\nfrom pathlib import Path\nfrom math import ceil\nfrom functools import partial, wraps\nfrom contextlib import nullcontext\nfrom collections.abc import Iterable\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR\nfrom torch.cuda.amp import autocast, GradScaler\nfrom dalle2_pytorch.dalle2_pytorch import Decoder, DiffusionPrior\nfrom dalle2_pytorch.optimizer import get_optimizer\nfrom dalle2_pytorch.version import __version__\nfrom packaging import version\nimport pytorch_warmup as warmup\nfrom ema_pytorch import EMA\nfrom accelerate import Accelerator, DistributedType\nimport numpy as np\n# helper functions\ndef exists(val):\n    return val is not None\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if callable(d) else d\ndef cast_tuple(val, length = 1):\n    return val if isinstance(val, tuple) else ((val,) * length)\ndef pick_and_pop(keys, d):\n    values = list(map(lambda key: d.pop(key), keys))\n    return dict(zip(keys, values))"
        },
        {
            "comment": "group_dict_by_key: Creates two dictionaries, one for keys that match the condition and another for those that do not, grouping by key.\nstring_begins_with: Returns a boolean value indicating whether a given string starts with a specified prefix.\ngroup_by_key_prefix: Groups dictionary items based on whether their keys start with a certain prefix.\ngroupby_prefix_and_trim: Similar to group_by_key_prefix, but also trims the common prefix from the keys and returns two dictionaries.\nnum_to_groups: Divides a given number into groups based on a specified divisor, appending any remainder to the last group.\ncast_torch_tensor: A decorator that wraps a function to cast its input and output tensors to specific devices.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":44-77",
            "content": "def group_dict_by_key(cond, d):\n    return_val = [dict(),dict()]\n    for key in d.keys():\n        match = bool(cond(key))\n        ind = int(not match)\n        return_val[ind][key] = d[key]\n    return (*return_val,)\ndef string_begins_with(prefix, str):\n    return str.startswith(prefix)\ndef group_by_key_prefix(prefix, d):\n    return group_dict_by_key(partial(string_begins_with, prefix), d)\ndef groupby_prefix_and_trim(prefix, d):\n    kwargs_with_prefix, kwargs = group_dict_by_key(partial(string_begins_with, prefix), d)\n    kwargs_without_prefix = dict(map(lambda x: (x[0][len(prefix):], x[1]), tuple(kwargs_with_prefix.items())))\n    return kwargs_without_prefix, kwargs\ndef num_to_groups(num, divisor):\n    groups = num // divisor\n    remainder = num % divisor\n    arr = [divisor] * groups\n    if remainder > 0:\n        arr.append(remainder)\n    return arr\n# decorators\ndef cast_torch_tensor(fn):\n    @wraps(fn)\n    def inner(model, *args, **kwargs):\n        device = kwargs.pop('_device', next(model.parameters()).device)\n        cast_device = kwargs.pop('_cast_device', True)"
        },
        {
            "comment": "This code handles argument casting and device assignment for a DeepSpeed-accelerated PyTorch model. It first checks if arguments are DeepSpeed precision types, then casts the tensors to the appropriate type if necessary. This ensures that the model's arguments are correctly prepared for training or evaluation within a DeepSpeed framework.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":78-98",
            "content": "        cast_deepspeed_precision = kwargs.pop('_cast_deepspeed_precision', True)\n        kwargs_keys = kwargs.keys()\n        all_args = (*args, *kwargs.values())\n        split_kwargs_index = len(all_args) - len(kwargs_keys)\n        all_args = tuple(map(lambda t: torch.from_numpy(t) if exists(t) and isinstance(t, np.ndarray) else t, all_args))\n        if cast_device:\n            all_args = tuple(map(lambda t: t.to(device) if exists(t) and isinstance(t, torch.Tensor) else t, all_args))\n        if cast_deepspeed_precision:\n            try:\n                accelerator = model.accelerator\n                if accelerator is not None and accelerator.distributed_type == DistributedType.DEEPSPEED:\n                    cast_type_map = {\n                        \"fp16\": torch.half,\n                        \"bf16\": torch.bfloat16,\n                        \"no\": torch.float\n                    }\n                    precision_type = cast_type_map[accelerator.mixed_precision]\n                    all_args = tuple(map(lambda t: t.to(precision_type) if exists(t) and isinstance(t, torch.Tensor) else t, all_args))"
        },
        {
            "comment": "This code defines functions for splitting arguments and keywords, as well as handling gradient accumulation. It includes a function to split an iterable into chunks of specified size (`split_iterable`), a `split` function for tensors and iterables, and a `find_first` function to find the first item in an array that meets a given condition. The last function defined is `split_args_and_kwargs`, which splits arguments and keywords based on a specified size.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":99-137",
            "content": "            except AttributeError:\n                # Then this model doesn't have an accelerator\n                pass\n        args, kwargs_values = all_args[:split_kwargs_index], all_args[split_kwargs_index:]\n        kwargs = dict(tuple(zip(kwargs_keys, kwargs_values)))\n        out = fn(model, *args, **kwargs)\n        return out\n    return inner\n# gradient accumulation functions\ndef split_iterable(it, split_size):\n    accum = []\n    for ind in range(ceil(len(it) / split_size)):\n        start_index = ind * split_size\n        accum.append(it[start_index: (start_index + split_size)])\n    return accum\ndef split(t, split_size = None):\n    if not exists(split_size):\n        return t\n    if isinstance(t, torch.Tensor):\n        return t.split(split_size, dim = 0)\n    if isinstance(t, Iterable):\n        return split_iterable(t, split_size)\n    return TypeError\ndef find_first(cond, arr):\n    for el in arr:\n        if cond(el):\n            return el\n    return None\ndef split_args_and_kwargs(*args, split_size = None, **kwargs):"
        },
        {
            "comment": "This code splits the input arguments and keyword arguments into chunks based on batch size, split size, and dictionary keys. It then yields the chunk size fraction and the split chunked arguments and keyword arguments for further processing.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":138-158",
            "content": "    all_args = (*args, *kwargs.values())\n    len_all_args = len(all_args)\n    first_tensor = find_first(lambda t: isinstance(t, torch.Tensor), all_args)\n    assert exists(first_tensor)\n    batch_size = len(first_tensor)\n    split_size = default(split_size, batch_size)\n    num_chunks = ceil(batch_size / split_size)\n    dict_len = len(kwargs)\n    dict_keys = kwargs.keys()\n    split_kwargs_index = len_all_args - dict_len\n    split_all_args = [split(arg, split_size = split_size) if exists(arg) and isinstance(arg, (torch.Tensor, Iterable)) else ((arg,) * num_chunks) for arg in all_args]\n    chunk_sizes = tuple(map(len, split_all_args[0]))\n    for (chunk_size, *chunked_all_args) in tuple(zip(chunk_sizes, *split_all_args)):\n        chunked_args, chunked_kwargs_values = chunked_all_args[:split_kwargs_index], chunked_all_args[split_kwargs_index:]\n        chunked_kwargs = dict(tuple(zip(dict_keys, chunked_kwargs_values)))\n        chunk_size_frac = chunk_size / batch_size\n        yield chunk_size_frac, (chunked_args, chunked_kwargs)"
        },
        {
            "comment": "This code defines a `DiffusionPriorTrainer` class that takes in a `diffusion_prior`, and allows for training with different batch sizes by splitting arguments and keywords into chunks. It also supports optional accelerator, learning rate, weight decay, epsilon, max gradient norm, grouped weight decay parameters, warmup steps, and cosine decay maximum steps.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":160-191",
            "content": "# diffusion prior trainer\ndef prior_sample_in_chunks(fn):\n    @wraps(fn)\n    def inner(self, *args, max_batch_size = None, **kwargs):\n        if not exists(max_batch_size):\n            return fn(self, *args, **kwargs)\n        outputs = [fn(self, *chunked_args, **chunked_kwargs) for _, (chunked_args, chunked_kwargs) in split_args_and_kwargs(*args, split_size = max_batch_size, **kwargs)]\n        return torch.cat(outputs, dim = 0)\n    return inner\nclass DiffusionPriorTrainer(nn.Module):\n    def __init__(\n        self,\n        diffusion_prior,\n        accelerator = None,\n        use_ema = True,\n        lr = 3e-4,\n        wd = 1e-2,\n        eps = 1e-6,\n        max_grad_norm = None,\n        group_wd_params = True,\n        warmup_steps = None,\n        cosine_decay_max_steps = None,\n        **kwargs\n    ):\n        super().__init__()\n        assert isinstance(diffusion_prior, DiffusionPrior)\n        ema_kwargs, kwargs = groupby_prefix_and_trim('ema_', kwargs)\n        accelerator_kwargs, kwargs = groupby_prefix_and_trim('accelerator_', kwargs)"
        },
        {
            "comment": "Checking if an accelerator is specified, assigning member variables for helpful operations, setting device and transferring model to that device, saving the diffusion prior model, and checking mixed precision settings if applicable.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":193-224",
            "content": "        if not exists(accelerator):\n            accelerator = Accelerator(**accelerator_kwargs)\n        # assign some helpful member vars\n        self.accelerator = accelerator\n        self.text_conditioned = diffusion_prior.condition_on_text_encodings\n        # setting the device\n        self.device = accelerator.device\n        diffusion_prior.to(self.device)\n        # save model\n        self.diffusion_prior = diffusion_prior\n        # mixed precision checks\n        if (\n            exists(self.accelerator) \n            and self.accelerator.distributed_type == DistributedType.DEEPSPEED \n            and self.diffusion_prior.clip is not None\n            ):\n            # Then we need to make sure clip is using the correct precision or else deepspeed will error\n            cast_type_map = {\n                \"fp16\": torch.half,\n                \"bf16\": torch.bfloat16,\n                \"no\": torch.float\n            }\n            precision_type = cast_type_map[accelerator.mixed_precision]\n            assert precision"
        },
        {
            "comment": "This code initializes the trainer for DeepSpeed, setting precision, optimizer, and scheduler. It checks if on-the-fly embedding generation from CLIP is supported and changes precision accordingly. It also distributes the model using HFA and applies exponential moving average techniques.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":224-248",
            "content": "_type == torch.float, \"DeepSpeed currently only supports float32 precision when using on the fly embedding generation from clip\"\n            self.diffusion_prior.clip.to(precision_type)\n        # optimizer stuff\n        self.optim_kwargs = dict(lr=lr, wd=wd, eps=eps, group_wd_params=group_wd_params)\n        self.optimizer = get_optimizer(\n            self.diffusion_prior.parameters(),\n            **self.optim_kwargs,\n            **kwargs\n        )\n        if exists(cosine_decay_max_steps):\n            self.scheduler = CosineAnnealingLR(self.optimizer, T_max = cosine_decay_max_steps)\n        else:\n            self.scheduler = LambdaLR(self.optimizer, lr_lambda = lambda _: 1.0)\n        self.warmup_scheduler = warmup.LinearWarmup(self.optimizer, warmup_period = warmup_steps) if exists(warmup_steps) else None\n        # distribute the model if using HFA\n        self.diffusion_prior, self.optimizer, self.scheduler = self.accelerator.prepare(self.diffusion_prior, self.optimizer, self.scheduler)\n        # exponential moving average stuff"
        },
        {
            "comment": "The code snippet initializes a trainer object with an option for exponential moving average (EMA), gradient clipping, and tracks steps internally. It also defines a save method to save the optimizer, scheduler, model state dictionaries, and warmup scheduler on the main process. Note that LambdaLR cannot be saved due to pickling issues.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":250-279",
            "content": "        self.use_ema = use_ema\n        if self.use_ema:\n            self.ema_diffusion_prior = EMA(self.accelerator.unwrap_model(self.diffusion_prior), **ema_kwargs)\n        # gradient clipping if needed\n        self.max_grad_norm = max_grad_norm\n        # track steps internally\n        self.register_buffer('step', torch.tensor([0], device = self.device))\n    # utility\n    def save(self, path, overwrite = True, **kwargs):\n        # only save on the main process\n        if self.accelerator.is_main_process:\n            print(f\"Saving checkpoint at step: {self.step.item()}\")\n            path = Path(path)\n            assert not (path.exists() and not overwrite)\n            path.parent.mkdir(parents = True, exist_ok = True)\n            # FIXME: LambdaLR can't be saved due to pickling issues\n            save_obj = dict(\n                optimizer = self.optimizer.state_dict(),\n                scheduler = self.scheduler.state_dict(),\n                warmup_scheduler = self.warmup_scheduler,\n                model = self.accelerator.unwrap_model(self.diffusion_prior).state_dict(),"
        },
        {
            "comment": "This code saves and loads a checkpoint for a diffusion prior trainer. It also handles saving the EMA (Exponential Moving Average) model separately for easy ema-only reload, and allows overwriting the learning rate if needed. The `load` method loads an entire trainer, including its optimizer and EMA.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":280-303",
            "content": "                version = version.parse(__version__),\n                step = self.step,\n                **kwargs\n            )\n            if self.use_ema:\n                save_obj = {\n                    **save_obj,\n                    'ema': self.ema_diffusion_prior.state_dict(),\n                    'ema_model': self.ema_diffusion_prior.ema_model.state_dict() # save the ema model specifically for easy ema-only reload\n                }\n            torch.save(save_obj, str(path))\n    def load(self, path_or_state, overwrite_lr = True, strict = True):\n        \"\"\"\n        Load a checkpoint of a diffusion prior trainer.\n        Will load the entire trainer, including the optimizer and EMA.\n        Params:\n            - path_or_state (str | torch): a path to the DiffusionPriorTrainer checkpoint file\n            - overwrite_lr (bool): wether or not to overwrite the stored LR with the LR specified in the new trainer\n            - strict (bool): kwarg for `torch.nn.Module.load_state_dict`, will force an exact checkpoint match"
        },
        {
            "comment": "This function loads a checkpoint from a specified path or dictionary, handling both string paths and existing dictionaries. It checks if the loaded version matches the current package version, then unwraps and loads the model's state dict, sets step values, and loads optimizer and scheduler states as well.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":305-326",
            "content": "        Returns:\n            loaded_obj (dict): The loaded checkpoint dictionary\n        \"\"\"\n        # all processes need to load checkpoint. no restriction here\n        if isinstance(path_or_state, str):\n            path = Path(path_or_state)\n            assert path.exists()\n            loaded_obj = torch.load(str(path), map_location=self.device)\n        elif isinstance(path_or_state, dict):\n            loaded_obj = path_or_state\n        if version.parse(__version__) != loaded_obj['version']:\n            print(f'loading saved diffusion prior at version {loaded_obj[\"version\"]} but current package version is at {__version__}')\n        # unwrap the model when loading from checkpoint\n        self.accelerator.unwrap_model(self.diffusion_prior).load_state_dict(loaded_obj['model'], strict = strict)\n        self.step.copy_(torch.ones_like(self.step, device=self.device) * loaded_obj['step'].to(self.device))\n        self.optimizer.load_state_dict(loaded_obj['optimizer'])\n        self.scheduler.load_state_dict(loaded_obj['scheduler'])"
        },
        {
            "comment": "This function handles the warmup step, updating the learning rate if needed, loading EMA diffusion prior state from a checkpoint, and performing model update with optimization.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":328-357",
            "content": "        # set warmupstep\n        if exists(self.warmup_scheduler):\n            self.warmup_scheduler.last_step = self.step.item()\n        # ensure new lr is used if different from old one\n        if overwrite_lr:\n            new_lr = self.optim_kwargs[\"lr\"]\n            for group in self.optimizer.param_groups:\n                group[\"lr\"] = new_lr if group[\"lr\"] > 0.0 else 0.0\n        if self.use_ema:\n            assert 'ema' in loaded_obj\n            self.ema_diffusion_prior.load_state_dict(loaded_obj['ema'], strict = strict)\n            # below might not be necessary, but I had a suspicion that this wasn't being loaded correctly\n            self.ema_diffusion_prior.ema_model.load_state_dict(loaded_obj[\"ema_model\"])\n        return loaded_obj\n    # model functionality\n    def update(self):\n        if exists(self.max_grad_norm):\n            self.accelerator.clip_grad_norm_(self.diffusion_prior.parameters(), self.max_grad_norm)\n        self.optimizer.step()\n        self.optimizer.zero_grad()\n        # accelerator will ocassionally skip optimizer steps in a \"dynamic loss scaling strategy\""
        },
        {
            "comment": "The code defines several methods for using the diffusion prior model to generate samples. It uses exponential moving average (EMA) for model averaging, if `use_ema` is enabled. The `p_sample_loop`, `sample`, and `sample_batch_size` methods use `torch.no_grad()` for performance optimization, and `cast_torch_tensor` and `prior_sample_in_chunks` decorators are used to process data in chunks.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":358-385",
            "content": "        if not self.accelerator.optimizer_step_was_skipped:\n            sched_context = self.warmup_scheduler.dampening if exists(self.warmup_scheduler) else nullcontext\n            with sched_context():\n                self.scheduler.step()\n        if self.use_ema:\n            self.ema_diffusion_prior.update()\n        self.step += 1\n    @torch.no_grad()\n    @cast_torch_tensor\n    @prior_sample_in_chunks\n    def p_sample_loop(self, *args, **kwargs):\n        model = self.ema_diffusion_prior.ema_model if self.use_ema else self.diffusion_prior\n        return model.p_sample_loop(*args, **kwargs)\n    @torch.no_grad()\n    @cast_torch_tensor\n    @prior_sample_in_chunks\n    def sample(self, *args, **kwargs):\n        model = self.ema_diffusion_prior.ema_model if self.use_ema else self.diffusion_prior\n        return model.sample(*args, **kwargs)\n    @torch.no_grad()\n    def sample_batch_size(self, *args, **kwargs):\n        model = self.ema_diffusion_prior.ema_model if self.use_ema else self.diffusion_prior\n        return model.sample_batch_size(*args, **kwargs)"
        },
        {
            "comment": "This code defines a trainer with a function `embed_text` that uses the unwrapped model for embedding text, and a `forward` method that performs forward pass in chunks to handle large batch sizes. The `decoder_sample_in_chunks` decorator enables chunking when sample decoding.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":387-422",
            "content": "    @torch.no_grad()\n    @cast_torch_tensor\n    @prior_sample_in_chunks\n    def embed_text(self, *args, **kwargs):\n        return self.accelerator.unwrap_model(self.diffusion_prior).clip.embed_text(*args, **kwargs)\n    @cast_torch_tensor\n    def forward(\n        self,\n        *args,\n        max_batch_size = None,\n        **kwargs\n    ):\n        total_loss = 0.\n        for chunk_size_frac, (chunked_args, chunked_kwargs) in split_args_and_kwargs(*args, split_size = max_batch_size, **kwargs):\n            with self.accelerator.autocast():\n                loss = self.diffusion_prior(*chunked_args, **chunked_kwargs)\n                loss = loss * chunk_size_frac\n            total_loss += loss.item()\n            if self.training:\n                self.accelerator.backward(loss)\n        return total_loss\n# decoder trainer\ndef decoder_sample_in_chunks(fn):\n    @wraps(fn)\n    def inner(self, *args, max_batch_size = None, **kwargs):\n        if not exists(max_batch_size):\n            return fn(self, *args, **kwargs)\n        if self.decoder.unconditional:"
        },
        {
            "comment": "The function is a trainer that takes a decoder, accelerator, and other parameters. It can handle batching the inputs or splitting arguments and keywords to train the decoder in chunks, depending on the size of input data. The returned inner function is used for training the model using the provided configuration.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":423-453",
            "content": "            batch_size = kwargs.get('batch_size')\n            batch_sizes = num_to_groups(batch_size, max_batch_size)\n            outputs = [fn(self, *args, **{**kwargs, 'batch_size': sub_batch_size}) for sub_batch_size in batch_sizes]\n        else:\n            outputs = [fn(self, *chunked_args, **chunked_kwargs) for _, (chunked_args, chunked_kwargs) in split_args_and_kwargs(*args, split_size = max_batch_size, **kwargs)]\n        return torch.cat(outputs, dim = 0)\n    return inner\nclass DecoderTrainer(nn.Module):\n    def __init__(\n        self,\n        decoder,\n        accelerator = None,\n        dataloaders = None,\n        use_ema = True,\n        lr = 1e-4,\n        wd = 1e-2,\n        eps = 1e-8,\n        warmup_steps = None,\n        cosine_decay_max_steps = None,\n        max_grad_norm = 0.5,\n        amp = False,\n        group_wd_params = True,\n        **kwargs\n    ):\n        super().__init__()\n        assert isinstance(decoder, Decoder)\n        ema_kwargs, kwargs = groupby_prefix_and_trim('ema_', kwargs)\n        self.accelerator = default(accelerator, Accelerator)"
        },
        {
            "comment": "The code initializes the trainer with specific configurations for each UNET in the decoder. It checks learning rate, weight decay, warmup steps, and cosine decay max steps for each UNET. If a UNET is an identity, it assigns no optimizer or scheduler. Otherwise, it gets an appropriate optimizer for the UNET's parameters.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":455-480",
            "content": "        self.num_unets = len(decoder.unets)\n        self.use_ema = use_ema\n        self.ema_unets = nn.ModuleList([])\n        self.amp = amp\n        # be able to finely customize learning rate, weight decay\n        # per unet\n        lr, wd, eps, warmup_steps, cosine_decay_max_steps = map(partial(cast_tuple, length = self.num_unets), (lr, wd, eps, warmup_steps, cosine_decay_max_steps))\n        assert all([unet_lr <= 1e-2 for unet_lr in lr]), 'your learning rate is too high, recommend sticking with 1e-4, at most 5e-4'\n        optimizers = []\n        schedulers = []\n        warmup_schedulers = []\n        for unet, unet_lr, unet_wd, unet_eps, unet_warmup_steps, unet_cosine_decay_max_steps in zip(decoder.unets, lr, wd, eps, warmup_steps, cosine_decay_max_steps):\n            if isinstance(unet, nn.Identity):\n                optimizers.append(None)\n                schedulers.append(None)\n                warmup_schedulers.append(None)\n            else:\n                optimizer = get_optimizer(\n                    unet.parameters(),"
        },
        {
            "comment": "The code initializes optimizers, optionally schedulers for learning rate adjustments, and an exponential moving average (EMA) for the UNETs. It also registers a buffer for tracking steps and handles gradient clipping if needed based on distributed type.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":481-509",
            "content": "                    lr = unet_lr,\n                    wd = unet_wd,\n                    eps = unet_eps,\n                    group_wd_params = group_wd_params,\n                    **kwargs\n                )\n                optimizers.append(optimizer)\n                if exists(unet_cosine_decay_max_steps):\n                    scheduler = CosineAnnealingLR(optimizer, T_max = unet_cosine_decay_max_steps)\n                else:\n                    scheduler = LambdaLR(optimizer, lr_lambda = lambda step: 1.0)\n                warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period = unet_warmup_steps) if exists(unet_warmup_steps) else None\n                warmup_schedulers.append(warmup_scheduler)\n                schedulers.append(scheduler)\n            if self.use_ema:\n                self.ema_unets.append(EMA(unet, **ema_kwargs))\n        # gradient clipping if needed\n        self.max_grad_norm = max_grad_norm\n        self.register_buffer('steps', torch.tensor([0] * self.num_unets))\n        if self.accelerator.distributed_type == DistributedType.DEEPSPEED and decoder.clip is not None:"
        },
        {
            "comment": "This code ensures that the correct precision is used by DeepSpeed and prepares the decoder, optimizers, and dataloaders for training. It converts the clip to the specified precision type, then prepares them using DeepSpeed's accelerator. The train_loader and val_loader are stored for later use.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":510-536",
            "content": "            # Then we need to make sure clip is using the correct precision or else deepspeed will error\n            cast_type_map = {\n                \"fp16\": torch.half,\n                \"bf16\": torch.bfloat16,\n                \"no\": torch.float\n            }\n            precision_type = cast_type_map[accelerator.mixed_precision]\n            assert precision_type == torch.float, \"DeepSpeed currently only supports float32 precision when using on the fly embedding generation from clip\"\n            clip = decoder.clip\n            clip.to(precision_type)\n        decoder, *optimizers = list(self.accelerator.prepare(decoder, *optimizers))\n        self.decoder = decoder\n        # prepare dataloaders\n        train_loader = val_loader = None\n        if exists(dataloaders):\n            train_loader, val_loader = self.accelerator.prepare(dataloaders[\"train\"], dataloaders[\"val\"])\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        # store optimizers\n        for opt_ind, optimizer in zip(range(len(optimizers)), optimizers):"
        },
        {
            "comment": "This code defines a class with optimizers, schedulers, and warmup schedulers. It also validates the unet number and returns the number of steps taken by a specific unet. The save function saves the model's state dict to a specified path.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":537-565",
            "content": "            setattr(self, f'optim{opt_ind}', optimizer)\n        # store schedulers\n        for sched_ind, scheduler in zip(range(len(schedulers)), schedulers):\n            setattr(self, f'sched{sched_ind}', scheduler)\n        # store warmup schedulers\n        self.warmup_schedulers = warmup_schedulers\n    def validate_and_return_unet_number(self, unet_number = None):\n        if self.num_unets == 1:\n            unet_number = default(unet_number, 1)\n        assert exists(unet_number) and 1 <= unet_number <= self.num_unets\n        return unet_number\n    def num_steps_taken(self, unet_number = None):\n        unet_number = self.validate_and_return_unet_number(unet_number)\n        return self.steps[unet_number - 1].item()\n    def save(self, path, overwrite = True, **kwargs):\n        path = Path(path)\n        assert not (path.exists() and not overwrite)\n        path.parent.mkdir(parents = True, exist_ok = True)\n        save_obj = dict(\n            model = self.accelerator.unwrap_model(self.decoder).state_dict(),"
        },
        {
            "comment": "This code snippet saves the model state, optimizer state, and scheduler state if they exist, and an optional Exponential Moving Average (EMA) state. It checks the version compatibility before loading the saved state dictionary.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":566-590",
            "content": "            version = __version__,\n            steps = self.steps.cpu(),\n            **kwargs\n        )\n        for ind in range(0, self.num_unets):\n            optimizer_key = f'optim{ind}'\n            scheduler_key = f'sched{ind}'\n            optimizer = getattr(self, optimizer_key)\n            scheduler = getattr(self, scheduler_key)\n            optimizer_state_dict = optimizer.state_dict() if exists(optimizer) else None\n            scheduler_state_dict = scheduler.state_dict() if exists(scheduler) else None\n            save_obj = {**save_obj, optimizer_key: optimizer_state_dict, scheduler_key: scheduler_state_dict}\n        if self.use_ema:\n            save_obj = {**save_obj, 'ema': self.ema_unets.state_dict()}\n        self.accelerator.save(save_obj, str(path))\n    def load_state_dict(self, loaded_obj, only_model = False, strict = True):\n        if version.parse(__version__) != version.parse(loaded_obj['version']):\n            self.accelerator.print(f'loading saved decoder at version {loaded_obj[\"version\"]}, but current package version is {__version__}')"
        },
        {
            "comment": "This code loads a model and its associated optimizers, schedulers, and warmup schedulers from the given path. It also checks if early-stopping (ema) was used and loads that as well. The function returns the loaded state of each component if only_model is True, otherwise it continues with training.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":592-621",
            "content": "        self.accelerator.unwrap_model(self.decoder).load_state_dict(loaded_obj['model'], strict = strict)\n        self.steps.copy_(loaded_obj['steps'])\n        if only_model:\n            return loaded_obj\n        for ind, last_step in zip(range(0, self.num_unets), self.steps.tolist()):\n            optimizer_key = f'optim{ind}'\n            optimizer = getattr(self, optimizer_key)\n            scheduler_key = f'sched{ind}'\n            scheduler = getattr(self, scheduler_key)\n            warmup_scheduler = self.warmup_schedulers[ind]\n            if exists(optimizer):\n                optimizer.load_state_dict(loaded_obj[optimizer_key])\n            if exists(scheduler):\n                scheduler.load_state_dict(loaded_obj[scheduler_key])\n            if exists(warmup_scheduler):\n                warmup_scheduler.last_step = last_step\n        if self.use_ema:\n            assert 'ema' in loaded_obj\n            self.ema_unets.load_state_dict(loaded_obj['ema'], strict = strict)\n    def load(self, path, only_model = False, strict = True):"
        },
        {
            "comment": "This function loads a saved state and returns it. It also provides access to the unets (U-Nets) in the model and allows incrementing the step of a specific unet. The update method updates the optimizer and scheduler for a specified unet.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":622-651",
            "content": "        path = Path(path)\n        assert path.exists()\n        loaded_obj = torch.load(str(path), map_location = 'cpu')\n        self.load_state_dict(loaded_obj, only_model = only_model, strict = strict)\n        return loaded_obj\n    @property\n    def unets(self):\n        return nn.ModuleList([ema.ema_model for ema in self.ema_unets])\n    def increment_step(self, unet_number):\n        assert 1 <= unet_number <= self.num_unets\n        unet_index_tensor = torch.tensor(unet_number - 1, device = self.steps.device)\n        self.steps += F.one_hot(unet_index_tensor, num_classes = len(self.steps))\n    def update(self, unet_number = None):\n        unet_number = self.validate_and_return_unet_number(unet_number)\n        index = unet_number - 1\n        optimizer = getattr(self, f'optim{index}')\n        scheduler = getattr(self, f'sched{index}')\n        if exists(self.max_grad_norm):\n            self.accelerator.clip_grad_norm_(self.decoder.parameters(), self.max_grad_norm)  # Automatically unscales gradients\n        optimizer.step()"
        },
        {
            "comment": "This code is responsible for the sampling process in a specific model. It uses gradient descent to optimize the model and updates the exponential moving average (EMA) unets if ema is enabled. The sample function enables evaluation mode, handles non-ema usage or disabled use_ema, and returns the output based on the input arguments. The distributed argument is used for multi-process sampling.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":652-682",
            "content": "        optimizer.zero_grad()\n        warmup_scheduler = self.warmup_schedulers[index]\n        scheduler_context = warmup_scheduler.dampening if exists(warmup_scheduler) else nullcontext\n        with scheduler_context():\n            scheduler.step()\n        if self.use_ema:\n            ema_unet = self.ema_unets[index]\n            ema_unet.update()\n        self.increment_step(unet_number)\n    @torch.no_grad()\n    @cast_torch_tensor\n    @decoder_sample_in_chunks\n    def sample(self, *args, **kwargs):\n        distributed = self.accelerator.num_processes > 1\n        base_decoder = self.accelerator.unwrap_model(self.decoder)\n        was_training = base_decoder.training\n        base_decoder.eval()\n        if kwargs.pop('use_non_ema', False) or not self.use_ema:\n            out = base_decoder.sample(*args, **kwargs, distributed = distributed)\n            base_decoder.train(was_training)\n            return out\n        trainable_unets = self.accelerator.unwrap_model(self.decoder).unets\n        base_decoder.unets = self.unets                  # swap in exponential moving averaged unets for sampling"
        },
        {
            "comment": "This code defines a function for embedding text and image using the decoder's CLIP module. It also restores the original training unets, casts torch tensors, validates and returns the correct unet number, and allows for conditional lowres image return.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":684-716",
            "content": "        output = base_decoder.sample(*args, **kwargs, distributed = distributed)\n        base_decoder.unets = trainable_unets             # restore original training unets\n        # cast the ema_model unets back to original device\n        for ema in self.ema_unets:\n            ema.restore_ema_model_device()\n        base_decoder.train(was_training)\n        return output\n    @torch.no_grad()\n    @cast_torch_tensor\n    @prior_sample_in_chunks\n    def embed_text(self, *args, **kwargs):\n        return self.accelerator.unwrap_model(self.decoder).clip.embed_text(*args, **kwargs)\n    @torch.no_grad()\n    @cast_torch_tensor\n    @prior_sample_in_chunks\n    def embed_image(self, *args, **kwargs):\n        return self.accelerator.unwrap_model(self.decoder).clip.embed_image(*args, **kwargs)\n    @cast_torch_tensor\n    def forward(\n        self,\n        *args,\n        unet_number = None,\n        max_batch_size = None,\n        return_lowres_cond_image=False,\n        **kwargs\n    ):\n        unet_number = self.validate_and_return_unet_number(unet_number)"
        },
        {
            "comment": "This code chunk splits the input arguments and keywords into multiple smaller chunks, then iterates over them to perform computations with auto-cast enabled. The resulting losses are accumulated, and if conditional images are returned, they are stacked together. Finally, the total loss is returned.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/trainer.py\":718-741",
            "content": "        total_loss = 0.\n        cond_images = []\n        for chunk_size_frac, (chunked_args, chunked_kwargs) in split_args_and_kwargs(*args, split_size = max_batch_size, **kwargs):\n            with self.accelerator.autocast():\n                loss_obj = self.decoder(*chunked_args, unet_number = unet_number, return_lowres_cond_image=return_lowres_cond_image, **chunked_kwargs)\n                # loss_obj may be a tuple with loss and cond_image\n                if return_lowres_cond_image:\n                    loss, cond_image = loss_obj\n                else:\n                    loss = loss_obj\n                    cond_image = None\n                loss = loss * chunk_size_frac\n                if cond_image is not None:\n                    cond_images.append(cond_image)\n            total_loss += loss.item()\n            if self.training:\n                self.accelerator.backward(loss)\n        if return_lowres_cond_image:\n            return total_loss, torch.stack(cond_images)\n        else:\n            return total_loss"
        }
    ]
}