{
    "summary": "This code offers efficient data retrieval classes for DALL-E 2, supports text conditioning and MPI distribution. It divides embedding reader objects into training, evaluation, and test sets using PyTorch Dataloaders, without specifying batch sizes.",
    "details": [
        {
            "comment": "The code defines a class called PriorEmbeddingDataset that wraps the EmbeddingReader class. It allows for simplified sample retrieval from various configurations of EmbeddingReader by enabling batch-based access to prior data, where text_conditioned and batch_size are parameters, along with start and stop indices for the range of data to be loaded.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/dataloaders/prior_loader.py\":0-39",
            "content": "from math import ceil\nfrom clip import tokenize\nfrom embedding_reader import EmbeddingReader\nfrom torch import from_numpy\nfrom torch.utils.data import IterableDataset, DataLoader\nclass PriorEmbeddingDataset(IterableDataset):\n    \"\"\"\n    PriorEmbeddingDataset is a wrapper of EmbeddingReader.\n    It enables one to simplify the logic necessary to yield samples from\n    the different EmbeddingReader configurations available.\n    \"\"\"\n    def __init__(\n        self,\n        text_conditioned: bool,\n        batch_size: int,\n        start: int,\n        stop: int,\n        image_reader,\n        text_reader: EmbeddingReader = None,\n    ) -> None:\n        super(PriorEmbeddingDataset).__init__()\n        self.text_conditioned = text_conditioned\n        if not self.text_conditioned:\n            self.text_reader = text_reader\n        self.image_reader = image_reader\n        self.start = start\n        self.stop = stop\n        self.batch_size = batch_size\n    def __len__(self):\n        return self.stop - self.start\n    def __iter__(self):"
        },
        {
            "comment": "The code defines a PriorEmbeddingDataset class for data loading in DALLE2-pytorch. It uses an image_reader and text_reader to load data in a batch, with optional text conditioning. It includes a __next__ method for iterating through the dataset and a set_start method for adjusting the starting point within the reader.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/dataloaders/prior_loader.py\":40-71",
            "content": "        # D.R.Y loader args\n        loader_args = dict(\n            batch_size=self.batch_size,\n            start=self.start,\n            end=self.stop,\n            show_progress=False,\n        )\n        # if the data requested is text conditioned, only load images\n        if self.text_conditioned:\n            self.loader = self.image_reader(**loader_args)\n        # otherwise, include text embeddings and bypass metadata\n        else:\n            self.loader = zip(\n                self.image_reader(**loader_args), self.text_reader(**loader_args)\n            )\n        # return the data loader in its formatted state\n        return self\n    def __next__(self):\n        try:\n            return self.get_sample()\n        except StopIteration:\n            raise StopIteration\n    def __str__(self):\n        return f\"<PriorEmbeddingDataset: start: {self.start}, stop: {self.stop}, len: {self.__len__()}>\"\n    def set_start(self, start):\n        \"\"\"\n        Adjust the starting point within the reader, useful for resuming an epoch"
        },
        {
            "comment": "This code defines a class with methods to manage data loading and distribution for the DALL-E 2 model. It supports text-conditioned or unconditioned data, preprocesses input into a common format, and distributes data across multiple ranks using MPI.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/dataloaders/prior_loader.py\":72-111",
            "content": "        \"\"\"\n        self.start = start\n    def get_start(self):\n        return self.start\n    def get_sample(self):\n        \"\"\"\n        pre-proocess data from either reader into a common format\n        \"\"\"\n        if self.text_conditioned:\n            image_embedding, caption = next(self.loader)\n            image_embedding = from_numpy(image_embedding)\n            tokenized_caption = tokenize(caption[\"caption\"].to_list(), truncate=True)\n            return image_embedding, tokenized_caption\n        else:\n            (image_embedding, _), (text_embedding, _) = next(self.loader)\n            image_embedding = from_numpy(image_embedding)\n            text_embedding = from_numpy(text_embedding)\n            return image_embedding, text_embedding\n# helper functions\ndef distribute_to_rank(start, stop, rank, world_size):\n    \"\"\"\n    Distribute data to each rank given the world size.\n    Return:\n        - New start and stop points for this rank.\n    \"\"\"\n    num_samples = int(stop - start)\n    per_rank = int(ceil((num_samples) / float(world_size)))"
        },
        {
            "comment": "The code is defining functions that calculate the start and stop points for a given rank, and another function to create an EmbeddingReader object based on URLs. It asserts that certain inputs are not None before proceeding, ensuring necessary information is provided.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/dataloaders/prior_loader.py\":113-148",
            "content": "    assert (\n        per_rank > 0\n    ), f\"Number of samples per rank must be larger than 0, (found: {per_rank})\"\n    rank_start = start + rank * per_rank\n    rank_stop = min(rank_start + per_rank, stop)\n    new_length = rank_stop - rank_start\n    assert (\n        new_length > 0\n    ), \"Calculated start and stop points result in a length of zero for this rank.\"\n    return rank_start, rank_stop\ndef get_reader(\n    text_conditioned: bool, img_url: str, meta_url: str = None, txt_url: str = None\n):\n    \"\"\"\n    Create an EmbeddingReader object from the specified URLs\n    get_reader() will always expect a url to image embeddings.\n    If text-conditioned, it will also expect a meta_url for the captions.\n    Otherwise, it will need txt_url for the matching text embeddings.\n    Returns an image_reader object if text-conditioned.\n    Otherwise it returns both an image_reader and a text_reader\n    \"\"\"\n    assert img_url is not None, \"Must supply a image url\"\n    if text_conditioned:\n        assert meta_url is not None, \"Must supply meta url if text-conditioned\""
        },
        {
            "comment": "This code defines a function to split an embedding reader object into training, evaluation, and optional test sets. It takes in the text conditioned flag, batch size, number of data points, and train/eval splits as input parameters. If text-conditioning is not enabled, it requires text embedding URLs as well and returns two readers.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/dataloaders/prior_loader.py\":150-186",
            "content": "        image_reader = EmbeddingReader(\n            embeddings_folder=img_url,\n            file_format=\"parquet_npy\",\n            # will assume the caption column exists and is the only one requested\n            meta_columns=[\"caption\"],\n            metadata_folder=meta_url,\n        )\n        return image_reader\n    # otherwise we will require text embeddings as well and return two readers\n    assert (\n        txt_url is not None\n    ), \"Must supply text embedding url if not text-conditioning\"\n    image_reader = EmbeddingReader(img_url, file_format=\"npy\")\n    text_reader = EmbeddingReader(txt_url, file_format=\"npy\")\n    return image_reader, text_reader\ndef make_splits(\n    text_conditioned: bool,\n    batch_size: int,\n    num_data_points: int,\n    train_split: float,\n    eval_split: float,\n    image_reader: EmbeddingReader,\n    text_reader: EmbeddingReader = None,\n    start=0,\n    rank=0,\n    world_size=1,\n):\n    \"\"\"\n    Split an embedding reader object as needed.\n    NOTE: make_splits() will infer the test set size from your train and eval."
        },
        {
            "comment": "This function takes various inputs like batch size, train and eval splits, readers, and starting point to create PyTorch Dataloaders for image-text pairs. It ensures the start position is within the reader's count, and if the specified data points count exceeds the available ones, it defaults to the remaining count.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/dataloaders/prior_loader.py\":188-209",
            "content": "    Input:\n        - text_conditioned: whether to prepare text-conditioned training data\n        - batch_size: the batch size for a single gpu\n        - num_data_points: the total number of data points you wish to train on\n        - train_split: the percentage of data you wish to train on\n        - eval_split: the percentage of data you wish to validate on\n        - image_reader: the image_reader you wish to split\n        - text_reader: the text_reader you want to split (if !text_conditioned)\n        - start: the starting point within your dataset\n        - rank: the rank of your worker\n        - world_size: the total world size of your distributed training run\n    Returns:\n        - PyTorch Dataloaders that yield tuples of (img, txt) data.\n    \"\"\"\n    assert start < image_reader.count, \"start position cannot exceed reader count.\"\n    # verify that the num_data_points does not exceed the max points\n    if num_data_points > (image_reader.count - start):\n        print(\n            \"Specified count is larger than what's available...defaulting to reader's count.\""
        },
        {
            "comment": "Computing split points for training and evaluation data sets based on the specified splits. Distributing the data to ranks according to the world size. Wrapping up the splits into a dictionary with start, stop, and batch_size parameters.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/dataloaders/prior_loader.py\":210-241",
            "content": "        )\n        num_data_points = image_reader.count\n    # compute split points\n    train_set_size = int(train_split * num_data_points)\n    eval_set_size = int(eval_split * num_data_points)\n    eval_start = train_set_size\n    eval_stop = int(eval_start + eval_set_size)\n    assert (\n        train_split + eval_split\n    ) < 1.0, \"Specified train and eval split is too large to infer a test split.\"\n    # distribute to rank\n    rank_train_start, rank_train_stop = distribute_to_rank(\n        start, train_set_size, rank, world_size\n    )\n    rank_eval_start, rank_eval_stop = distribute_to_rank(\n        train_set_size, eval_stop, rank, world_size\n    )\n    rank_test_start, rank_test_stop = distribute_to_rank(\n        eval_stop, num_data_points, rank, world_size\n    )\n    # wrap up splits into a dict\n    train_split_args = dict(\n        start=rank_train_start, stop=rank_train_stop, batch_size=batch_size\n    )\n    eval_split_args = dict(\n        start=rank_eval_start, stop=rank_eval_stop, batch_size=batch_size\n    )\n    test_split_args = dict("
        },
        {
            "comment": "Code is creating a PriorEmbeddingDataset for train, validation, and test datasets based on given arguments. If text_conditioned, it creates separate dictionaries for each dataset and passes them to the PriorEmbeddingDataset class; otherwise, it adds additional non-conditioned arguments for the same process.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/dataloaders/prior_loader.py\":242-270",
            "content": "        start=rank_test_start, stop=rank_test_stop, batch_size=batch_size\n    )\n    if text_conditioned:\n        # add the text-conditioned args to a unified dict\n        reader_args = dict(\n            text_conditioned=text_conditioned,\n            image_reader=image_reader,\n        )\n        train_split_args = dict(**reader_args, **train_split_args)\n        eval_split_args = dict(**reader_args, **eval_split_args)\n        test_split_args = dict(**reader_args, **test_split_args)\n        train = PriorEmbeddingDataset(**train_split_args)\n        val = PriorEmbeddingDataset(**eval_split_args)\n        test = PriorEmbeddingDataset(**test_split_args)\n    else:\n        # add the non-conditioned args to a unified dict\n        reader_args = dict(\n            text_conditioned=text_conditioned,\n            image_reader=image_reader,\n            text_reader=text_reader,\n        )\n        train_split_args = dict(**reader_args, **train_split_args)\n        eval_split_args = dict(**reader_args, **eval_split_args)\n        test_split_args = dict(**reader_args, **test_split_args)"
        },
        {
            "comment": "This code creates train, val, and test datasets using PriorEmbeddingDataset with specific args. DataLoaders are created without specifying batch sizes, so the true batch size is determined in PriorEmbeddingDataset. The loaders and datasets are returned for further processing.",
            "location": "\"/media/root/Toshiba XG3/works/DALLE2-pytorch/docs/src/dalle2_pytorch/dataloaders/prior_loader.py\":272-281",
            "content": "        train = PriorEmbeddingDataset(**train_split_args)\n        val = PriorEmbeddingDataset(**eval_split_args)\n        test = PriorEmbeddingDataset(**test_split_args)\n    # true batch size is specifed in the PriorEmbeddingDataset\n    train_loader = DataLoader(train, batch_size=None)\n    eval_loader = DataLoader(val, batch_size=None)\n    test_loader = DataLoader(test, batch_size=None)\n    return train_loader, eval_loader, test_loader"
        }
    ]
}